{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python API\n",
    "\n",
    "## Introduction\n",
    "\n",
    "There are various client APIs for DuckDB. DuckDB’s “native” API is C++, with “official” wrappers available for C, Python, R, Java, Node.js, WebAssembly/Wasm, ODBC API, Julia, and a Command Line Interface (CLI).\n",
    "\n",
    "In this notebook, we will explore the [DuckDB Python API](https://duckdb.org/docs/api/python/overview).\n",
    "\n",
    "## Datasets\n",
    "\n",
    "The following datasets are used in this notebook. You don't need to download them, they can be accessed directly from the notebook.\n",
    "\n",
    "- [cities.csv](https://open.gishub.org/data/duckdb/cities.csv)\n",
    "- [countries.csv](https://open.gishub.org/data/duckdb/countries.csv)\n",
    "\n",
    "## Installation\n",
    "\n",
    "Uncomment the following cell to install the required packages if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting duckdb\n",
      "  Obtaining dependency information for duckdb from https://files.pythonhosted.org/packages/2e/60/04503bb5bffe0edeccb223b275b487fbb006dc0fd23513ed2dac03641429/duckdb-0.9.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading duckdb-0.9.1-cp311-cp311-win_amd64.whl.metadata (798 bytes)\n",
      "Collecting duckdb-engine\n",
      "  Obtaining dependency information for duckdb-engine from https://files.pythonhosted.org/packages/f3/6c/17298ff413db694b87ce0e3eea1685ffe47987fb64e46cd6b673bac53177/duckdb_engine-0.9.2-py3-none-any.whl.metadata\n",
      "  Downloading duckdb_engine-0.9.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jupysql\n",
      "  Obtaining dependency information for jupysql from https://files.pythonhosted.org/packages/34/ca/4ea8ba339edb13f3cffcf76390b4f35f5f0478c994f254ccf1ae49104241/jupysql-0.10.2-py3-none-any.whl.metadata\n",
      "  Downloading jupysql-0.10.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting sqlalchemy>=1.3.22 (from duckdb-engine)\n",
      "  Obtaining dependency information for sqlalchemy>=1.3.22 from https://files.pythonhosted.org/packages/04/88/39f1f5570eb1d28704b4954c97ee91c3b5604f2949ab8ed40b33c90aaad9/SQLAlchemy-2.0.22-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading SQLAlchemy-2.0.22-cp311-cp311-win_amd64.whl.metadata (9.7 kB)\n",
      "Collecting prettytable (from jupysql)\n",
      "  Obtaining dependency information for prettytable from https://files.pythonhosted.org/packages/4d/81/316b6a55a0d1f327d04cc7b0ba9d04058cb62de6c3a4d4b0df280cbe3b0b/prettytable-3.9.0-py3-none-any.whl.metadata\n",
      "  Downloading prettytable-3.9.0-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from jupysql) (8.16.1)\n",
      "Collecting sqlparse (from jupysql)\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "     ---------------------------------------- 0.0/41.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.2/41.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from jupysql) (0.2.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from jupysql) (3.1.2)\n",
      "Collecting sqlglot>=11.3.7 (from jupysql)\n",
      "  Obtaining dependency information for sqlglot>=11.3.7 from https://files.pythonhosted.org/packages/c2/43/cb42bb4853275bc4e050b3640728dbead65b0502852ca5e42c60d7d52729/sqlglot-18.17.0-py3-none-any.whl.metadata\n",
      "  Downloading sqlglot-18.17.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting ploomber-core>=0.2.7 (from jupysql)\n",
      "  Obtaining dependency information for ploomber-core>=0.2.7 from https://files.pythonhosted.org/packages/be/a6/62b999fdc801d16d31d3f5b281a20094a02a61fc7578a93d0184d0f0cf62/ploomber_core-0.2.15-py3-none-any.whl.metadata\n",
      "  Downloading ploomber_core-0.2.15-py3-none-any.whl.metadata (498 bytes)\n",
      "Collecting jupysql-plugin (from jupysql)\n",
      "  Obtaining dependency information for jupysql-plugin from https://files.pythonhosted.org/packages/34/55/ddd63a65f7c9761f1f7b1d1c98568f5ea69835f8327c19f5e0e90fa0482c/jupysql_plugin-0.2.6-py3-none-any.whl.metadata\n",
      "  Downloading jupysql_plugin-0.2.6-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ploomber-core>=0.2.7->jupysql) (8.1.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ploomber-core>=0.2.7->jupysql) (6.0.1)\n",
      "Collecting posthog (from ploomber-core>=0.2.7->jupysql)\n",
      "  Obtaining dependency information for posthog from https://files.pythonhosted.org/packages/a7/73/35758818228c70348be4c3c66a76653c62e894e0e3c3461453c5341ca926/posthog-3.0.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading posthog-3.0.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from sqlalchemy>=1.3.22->duckdb-engine) (4.8.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.22->duckdb-engine)\n",
      "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/07/e2/91bf652b49f4a7cce91c63e4fe0da518153a52e5f33660f76f971c50ad0e/greenlet-3.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading greenlet-3.0.1-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: backcall in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (2.16.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (5.11.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from ipython->jupysql) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from jinja2->jupysql) (2.1.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from prettytable->jupysql) (0.2.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from jedi>=0.16->ipython->jupysql) (0.8.3)\n",
      "Requirement already satisfied: requests<3.0,>=2.7 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from posthog->ploomber-core>=0.2.7->jupysql) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from posthog->ploomber-core>=0.2.7->jupysql) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog->ploomber-core>=0.2.7->jupysql)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog->ploomber-core>=0.2.7->jupysql)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from posthog->ploomber-core>=0.2.7->jupysql) (2.8.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from stack-data->ipython->jupysql) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from stack-data->ipython->jupysql) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from stack-data->ipython->jupysql) (0.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vance\\anaconda3\\envs\\opencv4\\lib\\site-packages (from requests<3.0,>=2.7->posthog->ploomber-core>=0.2.7->jupysql) (2023.7.22)\n",
      "Downloading duckdb-0.9.1-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "   ---------------------------------------- 0.0/10.3 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/10.3 MB 12.9 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 1.2/10.3 MB 15.5 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.5/10.3 MB 20.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/10.3 MB 23.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.1/10.3 MB 25.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.3/10.3 MB 25.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.5/10.3 MB 26.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.6/10.3 MB 25.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.8/10.3 MB 26.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.3/10.3 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.3/10.3 MB 23.4 MB/s eta 0:00:00\n",
      "Downloading duckdb_engine-0.9.2-py3-none-any.whl (43 kB)\n",
      "   ---------------------------------------- 0.0/43.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 43.1/43.1 kB ? eta 0:00:00\n",
      "Downloading jupysql-0.10.2-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.6/87.6 kB 4.8 MB/s eta 0:00:00\n",
      "Downloading ploomber_core-0.2.15-py3-none-any.whl (21 kB)\n",
      "Downloading SQLAlchemy-2.0.22-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.6/2.1 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 32.4 MB/s eta 0:00:00\n",
      "Downloading sqlglot-18.17.0-py3-none-any.whl (324 kB)\n",
      "   ---------------------------------------- 0.0/324.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 324.6/324.6 kB 21.0 MB/s eta 0:00:00\n",
      "Downloading jupysql_plugin-0.2.6-py3-none-any.whl (376 kB)\n",
      "   ---------------------------------------- 0.0/376.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 376.7/376.7 kB 22.9 MB/s eta 0:00:00\n",
      "Downloading prettytable-3.9.0-py3-none-any.whl (27 kB)\n",
      "Downloading greenlet-3.0.1-cp311-cp311-win_amd64.whl (288 kB)\n",
      "   ---------------------------------------- 0.0/288.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 288.4/288.4 kB 17.4 MB/s eta 0:00:00\n",
      "Downloading posthog-3.0.2-py2.py3-none-any.whl (37 kB)\n",
      "Installing collected packages: monotonic, sqlparse, sqlglot, prettytable, greenlet, duckdb, backoff, sqlalchemy, posthog, ploomber-core, duckdb-engine, jupysql-plugin, jupysql\n",
      "Successfully installed backoff-2.2.1 duckdb-0.9.1 duckdb-engine-0.9.2 greenlet-3.0.1 jupysql-0.10.2 jupysql-plugin-0.2.6 monotonic-1.6 ploomber-core-0.2.15 posthog-3.0.2 prettytable-3.9.0 sqlalchemy-2.0.22 sqlglot-18.17.0 sqlparse-0.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " %pip install duckdb duckdb-engine jupysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Extensions\n",
    "\n",
    "DuckDB’s Python API provides functions for installing and loading extensions, which perform the equivalent operations to running the `INSTALL` and `LOAD` SQL commands, respectively. An example that installs and loads the [httpfs extension](https://duckdb.org/docs/extensions/httpfs) looks like follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.install_extension(\"httpfs\")\n",
    "con.load_extension(\"httpfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "DuckDB can ingest data from a wide variety of formats – both on-disk and in-memory. See the [data ingestion page](https://duckdb.org/docs/api/python/data_ingestion) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┐\n",
      "│  42   │\n",
      "│ int32 │\n",
      "├───────┤\n",
      "│    42 │\n",
      "└───────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "con.sql('SELECT 42').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬──────────────────┬─────────┬───────────┬───────────┬────────────┐\n",
       "│  id   │       name       │ country │ latitude  │ longitude │ population │\n",
       "│ int64 │     varchar      │ varchar │  double   │  double   │   int64    │\n",
       "├───────┼──────────────────┼─────────┼───────────┼───────────┼────────────┤\n",
       "│     1 │ Bombo            │ UGA     │    0.5833 │   32.5333 │      75000 │\n",
       "│     2 │ Fort Portal      │ UGA     │     0.671 │    30.275 │      42670 │\n",
       "│     3 │ Potenza          │ ITA     │    40.642 │    15.799 │      69060 │\n",
       "│     4 │ Campobasso       │ ITA     │    41.563 │    14.656 │      50762 │\n",
       "│     5 │ Aosta            │ ITA     │    45.737 │     7.315 │      34062 │\n",
       "│     6 │ Mariehamn        │ ALD     │    60.097 │    19.949 │      10682 │\n",
       "│     7 │ Ramallah         │ PSE     │  31.90294 │  35.20621 │      24599 │\n",
       "│     8 │ Vatican City     │ VAT     │  41.90001 │  12.44781 │        832 │\n",
       "│     9 │ Poitier          │ FRA     │  46.58329 │   0.33328 │      85960 │\n",
       "│    10 │ Clermont-Ferrand │ FRA     │  45.77998 │   3.08001 │     233050 │\n",
       "│     · │   ·              │  ·      │      ·    │      ·    │        ·   │\n",
       "│     · │   ·              │  ·      │      ·    │      ·    │        ·   │\n",
       "│     · │   ·              │  ·      │      ·    │      ·    │        ·   │\n",
       "│  1240 │ Tokyo            │ JPN     │  35.68502 │ 139.75141 │   35676000 │\n",
       "│  1241 │ Mumbai           │ IND     │  19.01699 │  72.85699 │   18978000 │\n",
       "│  1242 │ Paris            │ FRA     │  48.86669 │   2.33334 │    9904000 │\n",
       "│  1243 │ Santiago         │ CHL     │ -33.45001 │ -70.66704 │    5720000 │\n",
       "│  1244 │ Kolkata          │ IND     │  22.49497 │  88.32468 │   14787000 │\n",
       "│  1245 │ Rio de Janeiro   │ BRA     │ -22.92502 │ -43.22502 │   11748000 │\n",
       "│  1246 │ Sao Paulo        │ BRA     │ -23.55868 │ -46.62502 │   18845000 │\n",
       "│  1247 │ Sydney           │ AUS     │ -33.92001 │ 151.18518 │    4630000 │\n",
       "│  1248 │ Singapore        │ SGP     │   1.29303 │ 103.85582 │    5183700 │\n",
       "│  1249 │ Hong Kong        │ CHN     │  22.30498 │ 114.18501 │    7206000 │\n",
       "├───────┴──────────────────┴─────────┴───────────┴───────────┴────────────┤\n",
       "│ 1249 rows (20 shown)                                          6 columns │\n",
       "└─────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.read_csv('https://open.gishub.org/data/duckdb/cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬─────────────────────────┬─────────────┬─────────────┬──────────────┬──────────┬───────────┐\n",
       "│  id   │         Country         │ Alpha2_code │ Alpha3_code │ Numeric_code │ Latitude │ Longitude │\n",
       "│ int64 │         varchar         │   varchar   │   varchar   │    int64     │  double  │  double   │\n",
       "├───────┼─────────────────────────┼─────────────┼─────────────┼──────────────┼──────────┼───────────┤\n",
       "│     1 │ Afghanistan             │ AF          │ AFG         │            4 │     33.0 │      65.0 │\n",
       "│     2 │ Albania                 │ AL          │ ALB         │            8 │     41.0 │      20.0 │\n",
       "│     3 │ Algeria                 │ DZ          │ DZA         │           12 │     28.0 │       3.0 │\n",
       "│     4 │ American Samoa          │ AS          │ ASM         │           16 │ -14.3333 │    -170.0 │\n",
       "│     5 │ Andorra                 │ AD          │ AND         │           20 │     42.5 │       1.6 │\n",
       "│     6 │ Angola                  │ AO          │ AGO         │           24 │    -12.5 │      18.5 │\n",
       "│     7 │ Anguilla                │ AI          │ AIA         │          660 │    18.25 │  -63.1667 │\n",
       "│     8 │ Antarctica              │ AQ          │ ATA         │           10 │    -90.0 │       0.0 │\n",
       "│     9 │ Antigua and Barbuda     │ AG          │ ATG         │           28 │    17.05 │     -61.8 │\n",
       "│    10 │ Argentina               │ AR          │ ARG         │           32 │    -34.0 │     -64.0 │\n",
       "│     · │    ·                    │ ·           │  ·          │            · │      ·   │       ·   │\n",
       "│     · │    ·                    │ ·           │  ·          │            · │      ·   │       ·   │\n",
       "│     · │    ·                    │ ·           │  ·          │            · │      ·   │       ·   │\n",
       "│   234 │ Vanuatu                 │ VU          │ VUT         │          548 │    -16.0 │     167.0 │\n",
       "│   235 │ Venezuela               │ VE          │ VEN         │          862 │      8.0 │     -66.0 │\n",
       "│   236 │ Vietnam                 │ VN          │ VNM         │          704 │     16.0 │     106.0 │\n",
       "│   237 │ Virgin Islands, British │ VG          │ VGB         │           92 │     18.5 │     -64.5 │\n",
       "│   238 │ Virgin Islands, U.S.    │ VI          │ VIR         │          850 │  18.3333 │  -64.8333 │\n",
       "│   239 │ Wallis and Futuna       │ WF          │ WLF         │          876 │    -13.3 │    -176.2 │\n",
       "│   240 │ Western Sahara          │ EH          │ ESH         │          732 │     24.5 │     -13.0 │\n",
       "│   241 │ Yemen                   │ YE          │ YEM         │          887 │     15.0 │      48.0 │\n",
       "│   242 │ Zambia                  │ ZM          │ ZMB         │          894 │    -15.0 │      30.0 │\n",
       "│   243 │ Zimbabwe                │ ZW          │ ZWE         │          716 │    -20.0 │      30.0 │\n",
       "├───────┴─────────────────────────┴─────────────┴─────────────┴──────────────┴──────────┴───────────┤\n",
       "│ 243 rows (20 shown)                                                                     7 columns │\n",
       "└───────────────────────────────────────────────────────────────────────────────────────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.read_csv('https://open.gishub.org/data/duckdb/countries.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "DuckDB can also directly query Pandas DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┐\n",
       "│   a   │\n",
       "│ int64 │\n",
       "├───────┤\n",
       "│    42 │\n",
       "└───────┘"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = pd.DataFrame({'a': [42]})\n",
    "con.sql('SELECT * FROM pandas_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DuckDB can also ingest data from remote sources (e.g., HTTP, S3) and return a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>country</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bombo</td>\n",
       "      <td>UGA</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>32.5333</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fort Portal</td>\n",
       "      <td>UGA</td>\n",
       "      <td>0.6710</td>\n",
       "      <td>30.2750</td>\n",
       "      <td>42670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Potenza</td>\n",
       "      <td>ITA</td>\n",
       "      <td>40.6420</td>\n",
       "      <td>15.7990</td>\n",
       "      <td>69060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Campobasso</td>\n",
       "      <td>ITA</td>\n",
       "      <td>41.5630</td>\n",
       "      <td>14.6560</td>\n",
       "      <td>50762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aosta</td>\n",
       "      <td>ITA</td>\n",
       "      <td>45.7370</td>\n",
       "      <td>7.3150</td>\n",
       "      <td>34062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id         name country  latitude  longitude  population\n",
       "0   1        Bombo     UGA    0.5833    32.5333       75000\n",
       "1   2  Fort Portal     UGA    0.6710    30.2750       42670\n",
       "2   3      Potenza     ITA   40.6420    15.7990       69060\n",
       "3   4   Campobasso     ITA   41.5630    14.6560       50762\n",
       "4   5        Aosta     ITA   45.7370     7.3150       34062"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = con.read_csv('https://open.gishub.org/data/duckdb/cities.csv').df()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Conversion\n",
    "\n",
    "DuckDB supports converting query results efficiently to a variety of formats. See the [result conversion page](https://duckdb.org/docs/api/python/result_conversion) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42,)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('SELECT 42').fetchall()  # Python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>42</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   42\n",
       "0  42"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('SELECT 42').df()  # Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'42': array([42])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con.sql('SELECT 42').fetchnumpy()  # NumPy Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data to Disk\n",
    "\n",
    "DuckDB supports writing Relation objects directly to disk in a variety of formats. The [COPY](https://duckdb.org/docs/sql/statements/copy) statement can be used to write data to disk using SQL as an alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.sql('SELECT 42').write_parquet('out.parquet')  # Write to a Parquet file\n",
    "con.sql('SELECT 42').write_csv('out.csv')  # Write to a CSV file\n",
    "con.sql(\"COPY (SELECT 42) TO 'out.parquet'\")  # Copy to a parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistent Storage\n",
    "\n",
    "By default DuckDB operates on an **in-memory** database. That means that any tables that are created are not persisted to disk. Using the `.connect` method a connection can be made to a persistent database. Any data written to that connection will be persisted, and can be reloaded by re-connecting to the same file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a connection to a file called 'file.db'\n",
    "con = duckdb.connect('file.db')\n",
    "# create a table and load data into it\n",
    "con.sql(\n",
    "    'CREATE TABLE IF NOT EXISTS cities AS FROM read_csv_auto(\"https://open.gishub.org/data/duckdb/cities.csv\")'\n",
    ")\n",
    "# query the table\n",
    "con.table('cities').show()\n",
    "# Note: connections also closed implicitly when they go out of scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explicitly close the connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a context manager to ensure that the connection is closed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with duckdb.connect('file.db') as con:\n",
    "    con.sql(\n",
    "        'CREATE TABLE IF NOT EXISTS cities AS FROM read_csv_auto(\"https://open.gishub.org/data/duckdb/cities.csv\")'\n",
    "    )\n",
    "    con.table('cities').show()\n",
    "    # the context manager closes the connection automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Object and Module\n",
    "\n",
    "The connection object and the `duckdb` module can be used interchangeably – they support the same methods. The only difference is that when using the `duckdb` module a global in-memory database is used.\n",
    "\n",
    "Note that if you are developing a package designed for others to use, and use DuckDB in the package, it is recommend that you create connection objects instead of using the methods on the `duckdb` module. That is because the `duckdb` module uses a shared global database – which can cause hard to debug issues if used from within multiple different packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql('SELECT 42')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this one is recommended compared to codeblock above\n",
    "con = duckdb.connect()\n",
    "con.sql('SELECT 42')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [DuckDB Python API Overview](https://duckdb.org/docs/api/python/overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
